# Repository Cleanup Plan

A checklist for making this research repository professional, reproducible, and researcher-friendly.

---

## 0. Pre-Cleanup Safety (Do This First)

Before making any changes, protect the current working state:

```bash
# 1. Ensure all current work is committed
git add -A && git commit -m "Snapshot before repo cleanup"

# 2. Create a tag for rollback
git tag pre-cleanup && git push --tags

# 3. Create a cleanup branch (never clean up on main)
git checkout -b repo-cleanup
```

**Do not proceed until the above steps are complete.**

---

## 1. Data Policy (Raw .npy / Dataset Handling)

**Choose ONE option and document it in the README.**

| Option | When to Use | Implementation |
|--------|-------------|----------------|
| **A. Keep in repo** | Data < 50 MB total | Store under `data/raw/`, commit normally |
| **B. External download** | Data > 50 MB | Remove from git, add `scripts/download_data.py` with checksums |
| **C. Git LFS** | Large files needed in repo | `git lfs track "*.npy"`, document in README |

**Decision for this repo:** [Fill in after reviewing data sizes]

If using Option B, the download script must:
- Download from a stable URL (Zenodo, institutional server, or GitHub Release)
- Verify checksums after download
- Print clear success/failure messages

---

## 2. One Canonical Reproduction Entry Point

The repo MUST have exactly ONE primary reproduction workflow. Choose one:

| Option | File | When to Use |
|--------|------|-------------|
| **Makefile** | `make reproduce` | Unix environments, most common |
| **Script** | `scripts/reproduce.sh` | Cross-platform with bash |
| **Notebook** | `notebooks/reproduce_workflow.ipynb` | For interactive/Colab use |

**The README "Reproduce Results" section must point to exactly one of these.**

The reproduction workflow should execute:
```
1. Download/verify data (if external)
2. Run all identification methods
3. Train the selector model
4. Generate all figures
5. (Optional) Compile the paper
```

---

## 3. Dependency Pinning

For exact reproducibility, choose one:

- [ ] **Pin versions in `requirements.txt`** (e.g., `numpy==1.24.3`)
- [ ] **Add a lock file** (`requirements-lock.txt` or `uv.lock`)
- [ ] **Use conda environment.yml with pinned versions**

**Recommendation:** At minimum, pin major packages: numpy, pandas, scikit-learn, matplotlib.

---

## 4. File and Folder Cleanup

### Delete (confirmed safe to remove)

- [ ] `manuscript.zip` — Generated artifact, not needed in version control
- [ ] `.DS_Store` files — macOS artifacts (add to `.gitignore`)
- [ ] `__pycache__/`, `*.pyc` — Python bytecode (should be gitignored)

### Merge duplicates

- [ ] **Merge `config/` → `configs/`** — Single configuration directory

### Handle `dataset-Python/`

- [ ] Review contents
- [ ] If it contains raw data: move to `data/raw/`
- [ ] If it duplicates existing data: delete after confirming
- [ ] Document decision in commit message

### Handle `archive/` (legacy code)

**Do NOT delete blindly.** Choose one:

- [ ] **Option A: Rename to `legacy/`** and add `legacy/README.md` explaining:
  - "This directory contains historical code not required for reproduction."
  - "It is preserved for reference only."
- [ ] **Option B: Delete** only after running `grep -r "from archive" src/ scripts/` confirms nothing imports it

### Handle `models/` folder

If the folder exists:
- [ ] If empty and unused: **delete entirely**
- [ ] If used for trained artifacts: add `models/README.md` with:
  ```
  # Trained Model Artifacts
  
  This directory stores trained model files (.joblib, .pkl).
  These are NOT required for reproduction—they are regenerated by
  `scripts/train_models.py`. This folder is gitignored.
  ```

---

## 5. Essential Files to Add

- [ ] **`LICENSE`** — MIT or Apache 2.0 (required for open-source)
- [ ] **`CITATION.cff`** — Enables GitHub "Cite this repository" button

### Example CITATION.cff

```yaml
cff-version: 1.2.0
message: "If you use this software, please cite it as below."
title: "Meta-Learning Framework for PDE Identification Method Selection"
authors:
  - family-names: "Lende"
    given-names: "Pranav"
    affiliation: "Georgia Institute of Technology"
  - family-names: "Kang"
    given-names: "Sung Ha"
    affiliation: "Georgia Institute of Technology"
version: 1.0.0
date-released: 2025-12-19
repository-code: "https://github.com/ALLENDE123X/ident-lab"
license: MIT
```

---

## 6. Simplified Repository Structure

Target a clean, minimal structure:

```
WeakIdent-Python/
├── README.md              # Overview, install, reproduce
├── LICENSE
├── CITATION.cff
├── Makefile               # Primary entry: make reproduce
├── requirements.txt       # Pinned dependencies
├── pyproject.toml
│
├── src/                   # Core library code
├── scripts/               # All runnable scripts
├── data/                  # Data files
│   ├── raw/               # Original simulations
│   └── results/           # Generated outputs, figures, CSVs
├── manuscript/            # Paper source
│   ├── tower_paper.tex
│   ├── references.bib
│   ├── metrics.tex
│   └── figures/           # All paper figures
├── notebooks/             # Exploratory analysis (optional)
├── tests/                 # Unit tests
├── configs/               # Configuration files
│
├── .github/               # CI workflows
├── .gitignore
├── Dockerfile
└── docker-compose.yml
```

**Folders to omit unless actively used:**
- `experiments/` — Only if you're tracking dated runs with provenance
- `docs/` — Only if you have generated API docs
- `examples/` — Only if you have standalone demo scripts

---

## 7. README Requirements

The README must include:

- [ ] **One-liner description** with key result
- [ ] **Badges** (Python version, license, paper link)
- [ ] **Installation** (one command)
- [ ] **Reproduce Results** section pointing to single entry point
- [ ] **Citation** section

### Example README section

```markdown
## Reproduce Results

From a clean environment:

```bash
python -m venv venv && source venv/bin/activate
pip install -r requirements.txt
make reproduce  # Runs full pipeline: data → train → figures
```

Results will be in `data/results/` and `manuscript/figures/`.
```

---

## 8. Acceptance Criteria (Final Checklist)

Before merging cleanup branch, verify ALL of the following:

- [ ] README has a "Reproduce Results" section that works from a clean environment
- [ ] Exactly ONE reproduction entry point exists (`make reproduce` or equivalent)
- [ ] All scripts needed for reproduction are in `scripts/`
- [ ] All paper figures are in `manuscript/figures/`
- [ ] No large generated artifacts are committed (check with `git ls-files --others --ignored`)
- [ ] `requirements.txt` has pinned versions for core packages
- [ ] `CITATION.cff` is present and valid
- [ ] `LICENSE` is present
- [ ] No broken imports (run `python -c "import src"` or pytest)
- [ ] `.gitignore` excludes: `venv/`, `__pycache__/`, `.DS_Store`, `*.pyc`, `models/*.joblib`

---

## Execution Order

1. **Pre-cleanup safety** — Tag and branch
2. **Data decision** — Choose policy A/B/C
3. **Delete safe files** — `manuscript.zip`, `.DS_Store`
4. **Consolidate folders** — Merge duplicates
5. **Handle legacy code** — Rename or delete `archive/`
6. **Add required files** — LICENSE, CITATION.cff
7. **Pin dependencies** — Update requirements.txt
8. **Add reproduction entry** — `make reproduce`
9. **Update README** — Add badges, reproduce section
10. **Run acceptance checklist** — Verify all criteria
11. **Merge and push** — `git checkout main && git merge repo-cleanup`
